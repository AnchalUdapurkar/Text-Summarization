{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a9081cb",
   "metadata": {},
   "source": [
    "# Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2265f7",
   "metadata": {},
   "source": [
    "in extractive text summarization, the summary is created by selecting and extracting important sentencesor phrases directly from the orignal text without any modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53e10b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text for summarization\n",
    "text = \"Text summarization is a natural language processing (NLP) technique that aims to generate concise and meaningful summaries from large amounts of text data. This process is essential for extracting key information, reducing redundancy, and enhancing the efficiency of information retrieval. Text summarization can be applied in various domains such as news articles, research papers, and customer feedback analysis, enabling businesses to quickly grasp the most important insights. It can be implemented using techniques like extractive methods, which select significant portions of the text, or abstractive methods, which generate new summaries based on the text's meaning.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "821e2ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "673"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking lenght of Text\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f56a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the spaCy library for natural language processing\n",
    "# Import the stop words from spaCy\n",
    "# Import punctuation for text processing\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30971e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the English language model from spaCy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e5cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the text with the spaCy NLP pipeline\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d6527fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the text and removing stopwords and punctuation\n",
    "\n",
    "tokens = [token.text.lower() for token in doc if not token.is_stop and not token.is_punct and token.text != \"\\n\"]\n",
    "\n",
    "# This creates a list of tokens in lowercase that are not stopwords or punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "364be5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'summarization',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'nlp',\n",
       " 'technique',\n",
       " 'aims',\n",
       " 'generate',\n",
       " 'concise',\n",
       " 'meaningful',\n",
       " 'summaries',\n",
       " 'large',\n",
       " 'amounts',\n",
       " 'text',\n",
       " 'data',\n",
       " 'process',\n",
       " 'essential',\n",
       " 'extracting',\n",
       " 'key',\n",
       " 'information',\n",
       " 'reducing',\n",
       " 'redundancy',\n",
       " 'enhancing',\n",
       " 'efficiency',\n",
       " 'information',\n",
       " 'retrieval',\n",
       " 'text',\n",
       " 'summarization',\n",
       " 'applied',\n",
       " 'domains',\n",
       " 'news',\n",
       " 'articles',\n",
       " 'research',\n",
       " 'papers',\n",
       " 'customer',\n",
       " 'feedback',\n",
       " 'analysis',\n",
       " 'enabling',\n",
       " 'businesses',\n",
       " 'quickly',\n",
       " 'grasp',\n",
       " 'important',\n",
       " 'insights',\n",
       " 'implemented',\n",
       " 'techniques',\n",
       " 'like',\n",
       " 'extractive',\n",
       " 'methods',\n",
       " 'select',\n",
       " 'significant',\n",
       " 'portions',\n",
       " 'text',\n",
       " 'abstractive',\n",
       " 'methods',\n",
       " 'generate',\n",
       " 'new',\n",
       " 'summaries',\n",
       " 'based',\n",
       " 'text',\n",
       " 'meaning']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the tokens\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64b80093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing counter\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e568f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate word frequency using Counter\n",
    "\n",
    "word_frequency=Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "341e8d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'text': 5,\n",
       "         'summarization': 2,\n",
       "         'natural': 1,\n",
       "         'language': 1,\n",
       "         'processing': 1,\n",
       "         'nlp': 1,\n",
       "         'technique': 1,\n",
       "         'aims': 1,\n",
       "         'generate': 2,\n",
       "         'concise': 1,\n",
       "         'meaningful': 1,\n",
       "         'summaries': 2,\n",
       "         'large': 1,\n",
       "         'amounts': 1,\n",
       "         'data': 1,\n",
       "         'process': 1,\n",
       "         'essential': 1,\n",
       "         'extracting': 1,\n",
       "         'key': 1,\n",
       "         'information': 2,\n",
       "         'reducing': 1,\n",
       "         'redundancy': 1,\n",
       "         'enhancing': 1,\n",
       "         'efficiency': 1,\n",
       "         'retrieval': 1,\n",
       "         'applied': 1,\n",
       "         'domains': 1,\n",
       "         'news': 1,\n",
       "         'articles': 1,\n",
       "         'research': 1,\n",
       "         'papers': 1,\n",
       "         'customer': 1,\n",
       "         'feedback': 1,\n",
       "         'analysis': 1,\n",
       "         'enabling': 1,\n",
       "         'businesses': 1,\n",
       "         'quickly': 1,\n",
       "         'grasp': 1,\n",
       "         'important': 1,\n",
       "         'insights': 1,\n",
       "         'implemented': 1,\n",
       "         'techniques': 1,\n",
       "         'like': 1,\n",
       "         'extractive': 1,\n",
       "         'methods': 2,\n",
       "         'select': 1,\n",
       "         'significant': 1,\n",
       "         'portions': 1,\n",
       "         'abstractive': 1,\n",
       "         'new': 1,\n",
       "         'based': 1,\n",
       "         'meaning': 1})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing counter of tokens\n",
    "\n",
    "Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8afc7eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum frequency of any word\n",
    "\n",
    "max_frequncy = max(word_frequency.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bed0f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_frequncy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f717c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize word frequencies (optional, but useful for ranking)\n",
    "\n",
    "for word in word_frequency.keys():\n",
    "    word_frequency[word] = round(word_frequency[word]/max_frequncy,2)\n",
    "    \n",
    "# Normalize frequencies to a range from 0 to 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "215caacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'text': 1.0,\n",
       "         'summarization': 0.4,\n",
       "         'natural': 0.2,\n",
       "         'language': 0.2,\n",
       "         'processing': 0.2,\n",
       "         'nlp': 0.2,\n",
       "         'technique': 0.2,\n",
       "         'aims': 0.2,\n",
       "         'generate': 0.4,\n",
       "         'concise': 0.2,\n",
       "         'meaningful': 0.2,\n",
       "         'summaries': 0.4,\n",
       "         'large': 0.2,\n",
       "         'amounts': 0.2,\n",
       "         'data': 0.2,\n",
       "         'process': 0.2,\n",
       "         'essential': 0.2,\n",
       "         'extracting': 0.2,\n",
       "         'key': 0.2,\n",
       "         'information': 0.4,\n",
       "         'reducing': 0.2,\n",
       "         'redundancy': 0.2,\n",
       "         'enhancing': 0.2,\n",
       "         'efficiency': 0.2,\n",
       "         'retrieval': 0.2,\n",
       "         'applied': 0.2,\n",
       "         'domains': 0.2,\n",
       "         'news': 0.2,\n",
       "         'articles': 0.2,\n",
       "         'research': 0.2,\n",
       "         'papers': 0.2,\n",
       "         'customer': 0.2,\n",
       "         'feedback': 0.2,\n",
       "         'analysis': 0.2,\n",
       "         'enabling': 0.2,\n",
       "         'businesses': 0.2,\n",
       "         'quickly': 0.2,\n",
       "         'grasp': 0.2,\n",
       "         'important': 0.2,\n",
       "         'insights': 0.2,\n",
       "         'implemented': 0.2,\n",
       "         'techniques': 0.2,\n",
       "         'like': 0.2,\n",
       "         'extractive': 0.2,\n",
       "         'methods': 0.4,\n",
       "         'select': 0.2,\n",
       "         'significant': 0.2,\n",
       "         'portions': 0.2,\n",
       "         'abstractive': 0.2,\n",
       "         'new': 0.2,\n",
       "         'based': 0.2,\n",
       "         'meaning': 0.2})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bf3d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence tokenization\n",
    "\n",
    "sent_token = [sent.text for sent in doc.sents]\n",
    "\n",
    "# This creates a list of sentences from the processed document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5f8634e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Text summarization is a natural language processing (NLP) technique that aims to generate concise and meaningful summaries from large amounts of text data.',\n",
       " 'This process is essential for extracting key information, reducing redundancy, and enhancing the efficiency of information retrieval.',\n",
       " 'Text summarization can be applied in various domains such as news articles, research papers, and customer feedback analysis, enabling businesses to quickly grasp the most important insights.',\n",
       " \"It can be implemented using techniques like extractive methods, which select significant portions of the text, or abstractive methods, which generate new summaries based on the text's meaning.\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "778c9a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      "summarization\n",
      "is\n",
      "a\n",
      "natural\n",
      "language\n",
      "processing\n",
      "(NLP)\n",
      "technique\n",
      "that\n",
      "aims\n",
      "to\n",
      "generate\n",
      "concise\n",
      "and\n",
      "meaningful\n",
      "summaries\n",
      "from\n",
      "large\n",
      "amounts\n",
      "of\n",
      "text\n",
      "data.\n",
      "This\n",
      "process\n",
      "is\n",
      "essential\n",
      "for\n",
      "extracting\n",
      "key\n",
      "information,\n",
      "reducing\n",
      "redundancy,\n",
      "and\n",
      "enhancing\n",
      "the\n",
      "efficiency\n",
      "of\n",
      "information\n",
      "retrieval.\n",
      "Text\n",
      "summarization\n",
      "can\n",
      "be\n",
      "applied\n",
      "in\n",
      "various\n",
      "domains\n",
      "such\n",
      "as\n",
      "news\n",
      "articles,\n",
      "research\n",
      "papers,\n",
      "and\n",
      "customer\n",
      "feedback\n",
      "analysis,\n",
      "enabling\n",
      "businesses\n",
      "to\n",
      "quickly\n",
      "grasp\n",
      "the\n",
      "most\n",
      "important\n",
      "insights.\n",
      "It\n",
      "can\n",
      "be\n",
      "implemented\n",
      "using\n",
      "techniques\n",
      "like\n",
      "extractive\n",
      "methods,\n",
      "which\n",
      "select\n",
      "significant\n",
      "portions\n",
      "of\n",
      "the\n",
      "text,\n",
      "or\n",
      "abstractive\n",
      "methods,\n",
      "which\n",
      "generate\n",
      "new\n",
      "summaries\n",
      "based\n",
      "on\n",
      "the\n",
      "text's\n",
      "meaning.\n"
     ]
    }
   ],
   "source": [
    "# Calculate sentence scores\n",
    "\n",
    "sent_score = {}  # Dictionary to hold sentence scores\n",
    "for sent in sent_token:\n",
    "    for word in sent.split():  # Split the sentence into words\n",
    "        if word.lower() in word_frequency.keys():  # Check if the word is in the frequency dictionary\n",
    "            if sent not in sent_score.keys():  # If the sentence is not already in the score dictionary\n",
    "                sent_score[sent] = word_frequency[word]  # Initialize its score\n",
    "            else:\n",
    "                sent_score[sent] +=word_frequency[word]  # Add the word's frequency to the score\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c0b58bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text summarization is a natural language processing (NLP) technique that aims to generate concise and meaningful summaries from large amounts of text data.': 4.0,\n",
       " 'This process is essential for extracting key information, reducing redundancy, and enhancing the efficiency of information retrieval.': 1.7999999999999998,\n",
       " 'Text summarization can be applied in various domains such as news articles, research papers, and customer feedback analysis, enabling businesses to quickly grasp the most important insights.': 2.6,\n",
       " \"It can be implemented using techniques like extractive methods, which select significant portions of the text, or abstractive methods, which generate new summaries based on the text's meaning.\": 2.8000000000000003}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24044424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1bf1e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Text summarization is a natural language proce...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This process is essential for extracting key i...</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Text summarization can be applied in various d...</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It can be implemented using techniques like ex...</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Score\n",
       "0  Text summarization is a natural language proce...    4.0\n",
       "1  This process is essential for extracting key i...    1.8\n",
       "2  Text summarization can be applied in various d...    2.6\n",
       "3  It can be implemented using techniques like ex...    2.8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(sent_score.items()),columns=['Sentence','Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1837b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3eac048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top 'n' sentences (the summary)\n",
    "# Set the number of sentences for the summary\n",
    "# Get the top 'n' sentences based on their scores\n",
    "\n",
    "num_sentences = 2\n",
    "n = nlargest(num_sentences, sent_score, key=sent_score.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ded4399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the selected sentences into a final summary\n",
    "\n",
    "summary = \" \".join(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52d50b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text summarization is a natural language processing (NLP) technique that aims to generate concise and meaningful summaries from large amounts of text data. It can be implemented using techniques like extractive methods, which select significant portions of the text, or abstractive methods, which generate new summaries based on the text's meaning.\n"
     ]
    }
   ],
   "source": [
    "# Print the summary\n",
    "# Output the generated summary\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15c18c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a605cc56",
   "metadata": {},
   "source": [
    "Explanation of Key Steps:\n",
    "    \n",
    "Tokenization: This process breaks down the text into individual words (tokens) while removing irrelevant words (stopwords) and punctuation.\n",
    "\n",
    "Word Frequency Calculation: Counts how many times each word appears and normalizes these counts to a scale of 0 to 1.\n",
    "\n",
    "Sentence Scoring: Each sentence is scored based on the sum of the normalized word frequencies of the words it contains.\n",
    "\n",
    "Summary Extraction: The top sentences with the highest scores are selected to create a concise summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ee1b83",
   "metadata": {},
   "source": [
    "#### This code summarizes a given text by using Natural Language Processing (NLP) techniques. It uses spaCy to process the text, removing stopwords and punctuation, and then calculates the frequency of each word. Sentences are scored based on the sum of the frequencies of the words they contain. The code then extracts the top-scoring sentences to form a summary, based on a predefined number of sentences (num_sentences). In the end, it prints the summary by selecting the most relevant sentences from the original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120c9323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
